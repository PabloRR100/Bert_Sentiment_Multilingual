{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/app')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment Settings\n",
      "+---------+----------------------+\n",
      "| Python  |        3.7.7         |\n",
      "+---------+----------------------+\n",
      "| PyTorch |        1.5.0         |\n",
      "+---------+----------------------+\n",
      "|  GPUs   |          1           |\n",
      "+---------+----------------------+\n",
      "|  Cores  |          6           |\n",
      "+---------+----------------------+\n",
      "| Device  | Tesla P100-PCIE-16GB |\n",
      "+---------+----------------------+\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import config\n",
    "import dataset\n",
    "from model import BERTBaseUncased\n",
    "from train import train_fn, eval_fn\n",
    "from utils import print_current_config\n",
    "from beautifultable import BeautifulTable as BT\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics, model_selection\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.multiprocessing\n",
    "\n",
    "from transformers import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "\n",
    "\n",
    "\"\"\" CONFIG \"\"\"\n",
    "CUDA = torch.cuda.is_available()\n",
    "N_GPU = torch.cuda.device_count()\n",
    "DEVICE = 'cuda' if CUDA else 'cpu'\n",
    "WORKERS = torch.multiprocessing.cpu_count()\n",
    "print_current_config(CUDA, N_GPU, DEVICE, WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('data/jigsaw-toxic-comment-train.csv', usecols=['comment_text', 'toxic'])\n",
    "df2 = pd.read_csv('data/jigsaw-unintended-bias-train.csv', usecols=['comment_text', 'toxic'], engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is so cool. It's like, 'would you want yo...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thank you!! This would make my life a lot less...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text  toxic\n",
       "0  This is so cool. It's like, 'would you want yo...    0.0\n",
       "1  Thank you!! This would make my life a lot less...    0.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training samples = 223549 + 1737739 = 1961288\n"
     ]
    }
   ],
   "source": [
    "print('Total training samples = {} + {} = {}'.format(df1.shape[0], df2.shape[0], df1.shape[0] + df2.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat([df1,df2], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid = pd.read_csv('data/validation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7efda30f2950>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(ncols=2)\n",
    "df_train.toxic.hist(ax=axs[0])\n",
    "df_valid.toxic.hist(ax=axs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset.BERTDataset(\n",
    "    comment=df_train.comment_text.values,\n",
    "    target=df_train.toxic.values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset = dataset.BERTDataset(\n",
    "    comment=df_valid.comment_text.values,\n",
    "    target=df_valid.toxic.values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_last=False\n",
    "train_sampler, valid_sampler = None, None\n",
    "train_data_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=config.TRAIN_BATCH_SIZE,\n",
    "    num_workers=4,\n",
    "    drop_last=drop_last,\n",
    "    sampler=train_sampler\n",
    ")\n",
    "valid_data_loader = torch.utils.data.DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=config.VALID_BATCH_SIZE,\n",
    "    num_workers=1,\n",
    "    drop_last=drop_last,\n",
    "    sampler=valid_sampler\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BERTBaseUncased(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(105879, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (bert_drop): Dropout(p=0.3, inplace=False)\n",
       "  (out): Linear(in_features=1536, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BERTBaseUncased()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "optimizer_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.001},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0},\n",
    "]\n",
    "\n",
    "lr = config.LR\n",
    "num_train_steps = int(len(df_train) / config.TRAIN_BATCH_SIZE * config.EPOCHS)\n",
    "# TODO: why do the LR increases because of a distributed training ?\n",
    "if config.TPUs:\n",
    "    num_train_steps /= n_TPUs\n",
    "    lr *= n_TPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(optimizer_parameters, lr=lr)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_train_steps\n",
    ")\n",
    "\n",
    "if not config.TPUs:\n",
    "    if N_GPU > 1:\n",
    "        model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/245161 [00:00<?, ?it/s]/opt/conda/conda-bld/pytorch_1587428398394/work/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "  0%|          | 464/245161 [01:00<8:55:08,  7.62it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-c8aad912c76a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mtrain_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/app/train.py\u001b[0m in \u001b[0;36mtrain_fn\u001b[0;34m(data_loader, model, optimizer, device, scheduler)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPUs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mxm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "    \n",
    "for epoch in range(config.EPOCHS):\n",
    "\n",
    "    if config.TPUs:\n",
    "        train_loader = pl.ParallelLoader(train_data_loader, [device])\n",
    "        valid_loader = pl.ParallelLoader(valid_data_loader, [device])\n",
    "        train_fn(train_loader.per_device_loader(device), model, optimizer, device, scheduler)\n",
    "        outputs, targets = eval_fn(valid_loader.per_device_loader(device), model, device)\n",
    "\n",
    "    else:\n",
    "        train_fn(train_data_loader, model, optimizer, device, scheduler)\n",
    "        outputs, targets = eval_fn(valid_data_loader, model, device)\n",
    "\n",
    "    targets = np.array(targets) >= 0.5 # TODO: why ?\n",
    "    auc_score = metrics.roc_auc_score(targets, outputs)\n",
    "\n",
    "    # Save if best\n",
    "    print(f\"AUC Score = {auc_score}\")\n",
    "    if auc_score > best_score:\n",
    "        if not config.TPUs:\n",
    "            torch.save(model.state_dict(), config.MODEL_PATH)\n",
    "        else:\n",
    "            xm.save(model.state_dict(), config.MODEL_PATH)\n",
    "        best_score = auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
